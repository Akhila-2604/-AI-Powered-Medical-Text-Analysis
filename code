import pandas as pd
import numpy
import openai

from google.colab import drive
drive.mount('/content/drive')
media_research_articles = pd.read_excel('/content/drive/MyDrive/Data_set/Media & Research Articles data.xlsx')
twitter_posts = pd.read_excel('/content/drive/MyDrive/Data_set/Twitter Posts Data.xlsx')
media_research_articles.rename(columns={'Source': 'Source Type', 'Source Type': 'Source'},inplace=1)
media_research_articles.columns
twitter_posts=twitter_posts.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))

media_research_articles.drop('Article link',axis=1,inplace=True)
twitter_posts.drop('Post link',axis=1,inplace=True)
import re
for i in range(len(twitter_posts)):
  twitter_posts['Posts'][i]=' '.join(re.sub("(#[A-Za-z0-9]+)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)"," ",twitter_posts['Posts'][i]).split())
  twitter_posts['replied_to_tweet'][i]=' '.join(re.sub("(#[A-Za-z0-9]+)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)"," ",twitter_posts['replied_to_tweet'][i]).split())
twitter_posts.head()
media_research_articles.head()
twitter_posts.drop('HCP Handle',axis=1,inplace=True)
twitter_posts.head()
media_research_articles=media_research_articles.iloc[:, [0,1,2,3,5,4]]
twitter_posts=twitter_posts.iloc[:, [0,1,2,4,5,3]]
media_research_articles.rename(columns={'Article title':'Title'},inplace=True)
twitter_posts.rename(columns={'Posts':'Title','replied_to_tweet':'Content'},inplace=True)
combined_df = pd.concat([media_research_articles, twitter_posts], ignore_index=True,axis=0)
combined_df
combined_df['combined'] = combined_df['Title'] + ' ' + combined_df['Content']
combined_df.head()
# openai.api_key = "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"
# def analyze_text(text):
#   response = openai.completions.create(
#       model='gpt-3.5-turbo',
#       prompt=[
#           {"role": "system", "content": "You are an NLP Assistant. Perform entity recognition."},
#           {
#               "role":"user",
#               "content": f"""Analyse the following text:
#               extract key entities (Drugs,Diseases,Study Names).
#               text: {text}
#               """
#           }
#       ],
#       max_tokens=100
#   )
#   return response['choices'][0]['message']['content']

# for i in range(len(combined_df)):
#   combined_df['entity'][i]=analyze_text(combined_df['combined'][i])
# sample_text = "Aspirin is used to treat cardiovascular diseases."
# result = nlp(sample_text)
# print(result)

combined_df['entity'] = "n"
pip install -q -U google-generativeai
API_KEY = "AIzaSyBam890jDotYjjR6k7qJjQ8y_4Q_TEX-Fs"
import google.generativeai as genai
import os

genai.configure(api_key=API_KEY)
combined_df['entity']="n"
combined_df['topic']="n"
combined_df['sentiment']="n"
import textwrap
import time

def analyze_text_entity_recognition(text):
    model = genai.GenerativeModel(model_name='gemini-1.5-flash-8b')

    response = model.generate_content(
        textwrap.dedent(f"""\
        Please extract key entities from the following text:
        Identify the drugs, diseases, and study names mentioned in the text.

        Format the output as:
        {{
            "drugs": [{{"name": "drug_name"}}],
            "diseases": [{{"name": "disease_name"}}],
            "studyname": [{{"name": "study_name"}}]
        }}

        Important: Only return a single valid text in the above format.

        Here is the text:
        """) + text
    )

    return response.text
for i in range(len(combined_df)):
  combined_df.loc[i, "entity"] = analyze_text_entity_recognition(combined_df.loc[i, "combined"])
  time.sleep(3)
print(combined_df["entity"])
def analyze_text_topic_classification(text):
    model = genai.GenerativeModel(model_name="gemini-1.5-flash-8b")

    response = model.generate_content(
        textwrap.dedent(f"""\
        Please categorize the following text into the following relevant topics:
        Efficacy-General, Progression Free Survival (PFS), Overall Survival (OS), Safety-General, Safety-Side Effects, General Opinion, and Others.

        Format the output as:
        {{
            "efficacy_general": [{{"name": "topic_name"}}],
            "progression_free_survival": [{{"name": "topic_name"}}],
            "overall_survival": [{{"name": "topic_name"}}],
            "safety_general": [{{"name": "topic_name"}}],
            "safety_side_effects": [{{"name": "topic_name"}}],
            "general_opinion": [{{"name": "topic_name"}}],
            "others": [{{"name": "topic_name"}}]
        }}

        Important: Only return a single valid JSON text.

        Here is the text:
        """) + text
    )

    return response.text
for i in range(len(combined_df)):
  combined_df.loc[i, "topic"] = analyze_text_topic_classification(combined_df.loc[i, "combined"])
  time.sleep(5)
print(combined_df["topic"])
def analyze_text_sentiment(text):
    model = genai.GenerativeModel(model_name='gemini-1.5-flash-8b')

    response = model.generate_content(
        textwrap.dedent(f"""\
        Please return a JSON response indicating the sentiment expressed for each of the following topics:
        Efficacy-General, Progression Free Survival (PFS), Overall Survival (OS), Safety-General, Safety-Side Effects, General Opinion, and Others.

        Each topic should have its corresponding sentiment: positive, negative, or neutral.

        Format the output as:
        {{
            "efficacy_general": "sentiment",
            "progression_free_survival": "sentiment",
            "overall_survival": "sentiment",
            "safety_side_effects": "sentiment",
            "general_opinion": "sentiment",
            "others": "sentiment"
        }}

        Sentiment options:
        - positive
        - negative
        - neutral

        Important: Only return a single valid JSON text.

        Here is the text:
        """) + text
    )

    return response.text
for i in range(len(combined_df)):
  combined_df.loc[i, "sentiment"] = analyze_text_sentiment(combined_df.loc[i, "combined"])
  time.sleep(3)
print(combined_df["sentiment"])
combined_df["entity_temp"] = combined_df["entity"]
# combined_df["topic_temp"] = combined_df["topic"]
# combined_df["sentiment_temp"] = combined_df["sentiment"]
# print(combined_df["entity_temp"])
combined_df["entity"] = combined_df["entity_temp"]
# combined_df["topic"] = combined_df["topic_temp"]
# combined_df["sentiment"] = combined_df["sentiment_temp"]
print(combined_df["entity"][4])
combined_df["entity"][5]
import json
import re

def clean_string(input_string):
    """
    Parses a given JSON-like string with potential ```json and \n artifacts and ensures it is properly formatted.
    Args:
        input_string (str): The JSON-like string to parse and format.
    Returns:
        dict: Parsed JSON object if successful, None otherwise.
    """
    try:
        # Remove ```json and surrounding ``` if present
        cleaned_string = re.sub(r"```json|```", "", input_string)

        # Replace escaped newlines with actual newlines
        cleaned_string = cleaned_string.replace("\\n", "")

        # Try parsing the cleaned string as JSON
        parsed_data = json.loads(cleaned_string)
        return parsed_data
    except json.JSONDecodeError as e:
        print(f"Parsing failed: {e}")
        return None

# # Example usage
# json_string = combined_df["entity"][4]

# result = parse_and_format_json(json_string)
# if result:
#     print("Parsed JSON:")
#     print(json.dumps(result, indent=2))
# else:
#     print("Failed to parse the input string.")

for i in range(len(combined_df)):
  text = clean_string(combined_df["entity"][i])
  combined_df["entity"][i] = text
  # text = clean_string(combined_df["topic"][i])
  # combined_df["topic"][i] = text
  # text = clean_string(combined_df["sentiment"][i])
  # combined_df["sentiment"][i] = text
combined_df["entity_temp_temp"] = combined_df["entity"]
# combined_df["topic_temp_temp"] = combined_df["topic"]
# combined_df["sentiment_temp_temp"] = combined_df["sentiment"]
# print(combined_df["entity_temp_temp"])
print(combined_df["entity_temp_temp"][4])
combined_df["drug"]=" "

for i in range(len(combined_df)):
  # Check if the element is a dictionary and has the key "drugs"
  if isinstance(combined_df["entity_temp_temp"][i], dict) and "drugs" in combined_df["entity_temp_temp"][i]:
    for drug in combined_df["entity_temp_temp"][i]["drugs"]:
      combined_df['drug'][i] = combined_df['drug'][i] + drug["name"] + ","
for i in range(len(combined_df)):
  # Check if the element is a dictionary and has the key "drugs"
  if isinstance(combined_df["entity_temp_temp"][i], dict) and "diseases" in combined_df["entity_temp_temp"][i]:
    for disease in combined_df["entity_temp_temp"][i]["diseases"]:
      combined_df['diseases'][i] = combined_df['diseases'][i] + disease["name"] + ","
combined_df["study_name"]=" "
for i in range(len(combined_df)):
  # Check if the element is a dictionary and has the key "drugs"
  if isinstance(combined_df["entity_temp_temp"][i], dict) and "studyname" in combined_df["entity_temp_temp"][i]:
    for studyname in combined_df["entity_temp_temp"][i]["studyname"]:
      combined_df['study_name'][i] = combined_df['study_name'][i] + studyname["name"] + ","
print(combined_df["entity_temp_temp"][0])
print(combined_df["diseases"])
print(combined_df["drug"])
print(combined_df["study_name"])
for i in range(len(combined_df)):
  # Check if the element is a dictionary and has the key "drugs"
  if isinstance(combined_df["topic_temp_temp"][i], dict) and "drugs" in combined_df["entity_temp_temp"][i]:
    for drug in combined_df["entity_temp_temp"][i]["drugs"]:
      combined_df['drug'][i] = combined_df['drug'][i] + drug["name"] + ","
